{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c90d1bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the total number of training instnces are : 4 \n",
      " [['1', 'Sunny', 'warm', 'normal', 'strong', 'warm', 'same', 'yes'], ['2', 'Sunny', 'warm', 'high', 'strong', 'warm', 'same', 'yes'], ['3', 'Rainy', 'cold', 'high', 'strong', 'warm', 'change', 'no'], ['4', 'Sunny', 'warm', 'high', 'strong', 'cool', 'change', 'yes']]\n",
      "\n",
      " the hypothesis for the training instance 0 is:\n",
      " \n",
      " ['0', '0', '0', '0', '0', '0', '0'] \n",
      "\n",
      "\n",
      " the hypothesis for the training instance 1 is:\n",
      " \n",
      " ['1', 'Sunny', 'warm', 'normal', 'strong', 'warm', 'same'] \n",
      "\n",
      "\n",
      " the hypothesis for the training instance 2 is:\n",
      " \n",
      " ['?', 'Sunny', 'warm', '?', 'strong', 'warm', 'same'] \n",
      "\n",
      "\n",
      " the hypothesis for the training instance 3 is:\n",
      " \n",
      " ['?', 'Sunny', 'warm', '?', 'strong', 'warm', 'same'] \n",
      "\n",
      "\n",
      " the hypothesis for the training instance 4 is:\n",
      " \n",
      " ['?', 'Sunny', 'warm', '?', 'strong', '?', '?'] \n",
      "\n",
      "\n",
      " the maximally specific hypothesi for the training instance is ['?', 'Sunny', 'warm', '?', 'strong', '?', '?']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open ('enjoysports.csv','r') as file:\n",
    "    data=[row for row in csv.reader(file)]\n",
    "    print(\"the total number of training instnces are :\",len(data)-1,'\\n',data[1:])\n",
    "num_attribute=len(data[0])-1\n",
    "hypothesis=['0']*num_attribute #5 null values for specific hypotesis\n",
    "for i in range(0,len(data)):\n",
    "    if data[i][num_attribute]=='yes':\n",
    "        for j in range(0,num_attribute):\n",
    "            if hypothesis[j]=='0' or hypothesis[j]==data[i][j]:\n",
    "                hypothesis[j]=data[i][j]\n",
    "            else:\n",
    "                hypothesis[j]='?'\n",
    "    print('\\n the hypothesis for the training instance {} is:\\n'.format(i),'\\n',hypothesis,'\\n')\n",
    "   \n",
    "print('\\n the maximally specific hypothesi for the training instance is',hypothesis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c315a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The initialization of the specific and general hypothesis\n",
      "S0: ['0', '0', '0', '0', '0', '0', '0'] \n",
      "G0: ['?', '?', '?', '?', '?', '?', '?']\n",
      "\n",
      "The 1 training instance is Positive \n",
      " [1 'Sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
      "S1:\n",
      " [1 'Sunny' 'warm' 'normal' 'strong' 'warm' 'same']\n",
      "G1:\n",
      " [['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?']]\n",
      "\n",
      "The 2 training instance is Positive \n",
      " [2 'Sunny' 'warm' 'high' 'strong' 'warm' 'same']\n",
      "S2:\n",
      " ['?' 'Sunny' 'warm' '?' 'strong' 'warm' 'same']\n",
      "G2:\n",
      " [['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?']]\n",
      "\n",
      "The 3 training instance is Negative \n",
      " [3 'Rainy' 'cold' 'high' 'strong' 'warm' 'change']\n",
      "S3:\n",
      " ['?' 'Sunny' 'warm' '?' 'strong' 'warm' 'same']\n",
      "G3:\n",
      " [['?', '?', '?', '?', '?', '?', '?'], ['?', 'Sunny', '?', '?', '?', '?', '?'], ['?', '?', 'warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', 'same']]\n",
      "\n",
      "The 4 training instance is Positive \n",
      " [4 'Sunny' 'warm' 'high' 'strong' 'cool' 'change']\n",
      "S4:\n",
      " ['?' 'Sunny' 'warm' '?' 'strong' '?' '?']\n",
      "G4:\n",
      " [['?', '?', '?', '?', '?', '?', '?'], ['?', 'Sunny', '?', '?', '?', '?', '?'], ['?', '?', 'warm', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?'], ['?', '?', '?', '?', '?', '?', '?']]\n",
      "\n",
      "The Final Specific Hypothesis:\n",
      "['?' 'Sunny' 'warm' '?' 'strong' '?' '?']\n",
      "\n",
      "The Final General Hypothesis:\n",
      "[['?', 'Sunny', '?', '?', '?', '?', '?'], ['?', '?', 'warm', '?', '?', '?', '?']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from a CSV file\n",
    "data = pd.read_csv('enjoysports.csv')\n",
    "\n",
    "# Extract concepts (features) and target (class labels)\n",
    "concepts = data.iloc[:, :-1].values\n",
    "target = data.iloc[:, -1].values\n",
    "\n",
    "# Determine the number of attributes in each concept\n",
    "n = len(concepts[0])\n",
    "\n",
    "# Initialize specific and general hypotheses\n",
    "specific_h = ['0'] * n\n",
    "general_h = ['?'] * n\n",
    "\n",
    "print(\"The initialization of the specific and general hypothesis\")\n",
    "print(\"S0:\", specific_h, \"\\nG0:\", general_h)\n",
    "\n",
    "def learn(concepts, target):\n",
    "    # Initialize specific hypothesis with the first positive instance\n",
    "    specific_h = concepts[0].copy()\n",
    "\n",
    "    # Initialize general hypothesis as a list of lists with all '?'\n",
    "    general_h = [[\"?\" for _ in range(len(specific_h))] for _ in range(len(specific_h))]\n",
    "\n",
    "    for i, h in enumerate(concepts):\n",
    "        if target[i] == \"yes\":\n",
    "            print(f\"\\nThe {i+1} training instance is Positive \\n\", concepts[i])\n",
    "\n",
    "            # For positive instances, update the specific hypothesis\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    specific_h[x] = '?'\n",
    "                    general_h[x][x] = '?'\n",
    "        else:\n",
    "            print(f\"\\nThe {i+1} training instance is Negative \\n\", concepts[i])\n",
    "\n",
    "            # For negative instances, update the general hypothesis\n",
    "            for x in range(len(specific_h)):\n",
    "                if h[x] != specific_h[x]:\n",
    "                    general_h[x][x] = specific_h[x]\n",
    "                else:\n",
    "                    general_h[x][x] = '?'\n",
    "\n",
    "        print(f\"S{i+1}:\\n\", specific_h)\n",
    "        print(f\"G{i+1}:\\n\", general_h)\n",
    "\n",
    "    # Filter out redundant general hypotheses\n",
    "    general_h = [h for h in general_h if h != ['?' for _ in range(len(specific_h))]]\n",
    "    return specific_h, general_h\n",
    "\n",
    "# Learn the specific and general hypotheses from the data\n",
    "s_final, g_final = learn(concepts, target)\n",
    "\n",
    "print(\"\\nThe Final Specific Hypothesis:\")\n",
    "print(s_final)\n",
    "print(\"\\nThe Final General Hypothesis:\")\n",
    "print(g_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52957d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the data from a CSV file\n",
    "data = pd.read_csv('enjoysports.csv')\n",
    "\n",
    "# Extract concepts (features) and target (class labels)\n",
    "concepts = data.iloc[:, :-1].values\n",
    "target = data.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b29f2274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 'Sunny' 'warm' 'high' 'strong' 'warm' 'same']\n"
     ]
    }
   ],
   "source": [
    "print(concepts[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2126517f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "print(target[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f5ec82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "[[0.66666667 1.        ]\n",
      " [0.33333333 0.55555556]\n",
      " [1.         0.66666667]]\n",
      "Actual Output:\n",
      "[[0.92]\n",
      " [0.86]\n",
      " [0.89]]\n",
      "Predicted output:\n",
      " [[0.89597213]\n",
      " [0.88059393]\n",
      " [0.89327563]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array(([2,9],[1,5],[3,6]),dtype=float)\n",
    "y = np.array(([92],[86],[89]),dtype=float)\n",
    "X = X/np.amax(X,axis=0)\n",
    "y = y/100\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def derivatives_sigmoid(x):\n",
    "    return x*(1-x)\n",
    "\n",
    "epoch=5000\n",
    "lr=0.1\n",
    "inputlayer_neurons=2\n",
    "hiddenlayer_neurons=3\n",
    "output_neurons=1\n",
    "wh=np.random.uniform(size=(inputlayer_neurons,hiddenlayer_neurons))\n",
    "bh=np.random.uniform(size=(1,hiddenlayer_neurons))\n",
    "wout=np.random.uniform(size=(hiddenlayer_neurons,output_neurons))\n",
    "bout=np.random.uniform(size=(1,output_neurons))\n",
    "\n",
    "for i in range(epoch):\n",
    "    hinp1=np.dot(X,wh)\n",
    "    hinp=hinp1+bh\n",
    "    hlayer_act=sigmoid(hinp)\n",
    "    outinp1=np.dot(hlayer_act,wout)\n",
    "    outinp=outinp1+bout\n",
    "    output=sigmoid(outinp)\n",
    "    EO=y-output\n",
    "    outgrad=derivatives_sigmoid(output)\n",
    "    d_output=EO*outgrad\n",
    "    EH=d_output.dot(wout.T)\n",
    "    hiddengrad=derivatives_sigmoid(hlayer_act)\n",
    "    d_hiddenlayer=EH*hiddengrad\n",
    "    wout += hlayer_act.T.dot(d_output)*lr\n",
    "    wh +=X.T.dot(d_hiddenlayer)*lr\n",
    "\n",
    "print(\"Input:\\n\" +str(X))\n",
    "print(\"Actual Output:\\n\" +str(y))\n",
    "print(\"Predicted output:\\n\",output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11420be2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['num_preg', 'glucose_conc', 'diastolic bp', 'thickness', 'insulin',\\n       'bmi', 'diab_pred', 'age'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28076\\487707480.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mpredicted_class_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'diabetes'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Prepare features and target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature_col_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredicted_class_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Split data into train and test sets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3509\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3510\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3511\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3513\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5794\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5796\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5798\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5854\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5855\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5856\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5857\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5858\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['num_preg', 'glucose_conc', 'diastolic bp', 'thickness', 'insulin',\\n       'bmi', 'diab_pred', 'age'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "# Load data\n",
    "df = pd.read_csv('diabetes.csv')\n",
    "# Define feature columns and predicted class names\n",
    "feature_col_names = ['Pregnancies','Glucose','BloodPressure','SkinThickness','Insulin','BMI','DiabetesPedigreeFunction','Age'] \n",
    "predicted_class_names = ['Outcome']\n",
    "# Prepare features and target variable\n",
    "X = df[feature_col_names].values\n",
    "y = df[predicted_class_names].values\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "print('Total number of Training Data:', y_train.shape)\n",
    "print('Total number of Test Data:', y_test.shape)\n",
    "# Train Naive Bayes (NB) classifier\n",
    "clf=GaussianNB() \n",
    "clf.fit(X_train, y_train)\n",
    "# Predictions\n",
    "predicted = clf.predict(X_test)\n",
    "predict_test_data = clf.predict([[6, 148, 72, 35, 0, 33.6, 0.627, 50]])\n",
    "# Model Evaluation\n",
    "print(\"\\nConfusion matrix:\")\n",
    "print(metrics.confusion_matrix(y_test, predicted))\n",
    "print('\\nAccuracy of the classifier:', metrics.accuracy_score(y_test, predicted))\n",
    "print('\\nPrecision:', metrics.precision_score (y_test, predicted))\n",
    "print('\\nRecall:', metrics.recall_score(y_test, predicted))\n",
    "print(\"\\nPredicted Value for individual Test Data:\", predict_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faec69a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
